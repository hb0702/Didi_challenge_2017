{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from full_view_model import fcn_model\n",
    "from util_func import *\n",
    "from full_view_train import *\n",
    "from test_on_udacity_data import *\n",
    "from convert_to_full_view_panorama import *\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "get_custom_objects().update({\"my_loss\": my_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/split_1_grad/concat:0' shape=(?, 16, 320, 8) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "# load trained model\n",
    "model = load_model('./saved_model/fv_model_for_car_June_28_46.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list_of_view):  17977\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/training_didi_data/car_train_edited/'\n",
    "list_of_view = list_of_data(data_dir)\n",
    "print('len(list_of_view): ', len(list_of_view))\n",
    "#list_of_view = ['./data/training_didi_data/car_train_edited/suburu_leading_front_left/view/view_281.npy',\n",
    "#                './data/training_didi_data/car_train_edited/cmax_following_long/view/view_6631.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/training_didi_data/car_train_edited/suburu_driving_towards_it/lidar/lidar_196.npy\n",
      "./data/training_didi_data/car_train_gt_box_edited/suburu_driving_towards_it/gt_boxes3d/gt_boxes3d_196.npy\n"
     ]
    }
   ],
   "source": [
    "list_of_lidar = [file.replace('view','lidar') for file in list_of_view]\n",
    "list_of_gtbox = [file.replace('car_train_edited', 'car_train_gt_box_edited').replace('view','gt_boxes3d') \n",
    "                 for file in list_of_view]\n",
    "print(list_of_lidar[0])\n",
    "print(list_of_gtbox[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and clustering predicted box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_box_clustering(boxes, eps = 1, min_samples = 3):\n",
    "    # Extract the center from predicted boxes\n",
    "    box_centers = np.mean(boxes[:,[0,2],:2], axis = 1)\n",
    "    # Do clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(box_centers)\n",
    "    labels = db.labels_\n",
    "       \n",
    "    n_clusters = len(set(labels))\n",
    "    n_points = [np.sum([labels == i]) for i in range(n_clusters) ]\n",
    "    max_point_cluster = np.argmax(n_points)\n",
    "    \n",
    "    index = (labels == max_point_cluster)\n",
    "    box = np.mean(boxes[index],axis = 0)\n",
    "    return np.expand_dims(box, 0)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def predict(model,lidar, cluster = True, seg_thres=0.5, \n",
    "            cluster_dist = 0.2, min_dist = 2, neigbor_thres = 5):\n",
    "    \n",
    "    test_view =  fv_cylindrical_projection_for_test(lidar)\n",
    "    \n",
    "    view = test_view[:,:,[5,2]].reshape(1,16,320,2)\n",
    "    \n",
    "    list_boxes = []\n",
    "\n",
    "    test_view_reshape = test_view.reshape(-1,6)\n",
    "    pred = model.predict(view)\n",
    "    pred = pred[0].reshape(-1,8)\n",
    "    \n",
    "    thres_pred = pred[pred[:,0] > seg_thres]\n",
    "    thres_view = test_view_reshape[pred[:,0] > seg_thres]\n",
    "    \n",
    "    \n",
    "    num_boxes = len(thres_pred)\n",
    "    if num_boxes == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    boxes = np.zeros((num_boxes,8,3))\n",
    "    \n",
    "    for i in range(num_boxes):\n",
    "        boxes[i,0] = thres_view[i,:3] - rotation(thres_view[i,3],thres_pred[i,1:4])\n",
    "        boxes[i,6] = thres_view[i,:3] - rotation(thres_view[i,3],thres_pred[i,4:7])\n",
    "\n",
    "        boxes[i,2,:2] = boxes[i,6,:2]\n",
    "        boxes[i,2,2] = boxes[i,0,2]\n",
    "\n",
    "        phi = thres_pred[i,-1]\n",
    "\n",
    "        z = boxes[i,2] - boxes[i,0]\n",
    "        boxes[i,1,0] = (np.cos(phi)*z[0] + np.sin(phi)*z[1])*np.cos(phi) + boxes[i,0,0]\n",
    "        boxes[i,1,1] = (-np.sin(phi)*z[0] + np.cos(phi)*z[1])*np.cos(phi) + boxes[i,0,1]\n",
    "        boxes[i,1,2] = boxes[i,0,2]\n",
    "\n",
    "        boxes[i,3] = boxes[i,0] + boxes[i,2] - boxes[i,1]\n",
    "        boxes[i,4] = boxes[i,0] + boxes[i,6] - boxes[i,2]\n",
    "        boxes[i,5] = boxes[i,1] + boxes[i,4] - boxes[i,0]\n",
    "        boxes[i,7] = boxes[i,4] + boxes[i,6] - boxes[i,5]\n",
    "    list_boxes.append(boxes)\n",
    "\n",
    "    boxes = np.concatenate(list_boxes, axis = 0)\n",
    "    if not cluster:\n",
    "        return boxes\n",
    "    \n",
    "    else:\n",
    "        box_cluster = one_box_clustering(boxes)\n",
    "\n",
    "    return boxes, box_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly choose a frame \n",
    "i = np.random.randint(len(list_of_lidar))\n",
    "lidar = np.load(list_of_lidar[i])\n",
    "gtbox = np.load(list_of_gtbox[i])\n",
    "\n",
    "boxes, box_cluster = predict(model, lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 8, 3)\n",
      "(1, 8, 3)\n",
      "Number of predited boxes: 13\n",
      "Number of boxes after clustering: 1\n",
      "Randomly display 10 boxes then display clustered boxes\n"
     ]
    }
   ],
   "source": [
    "print(boxes.shape), print(box_cluster.shape)\n",
    "n_boxes = len(boxes)\n",
    "print('Number of predited boxes: {}'.format(n_boxes))\n",
    "print('Number of boxes after clustering: {}'.format(len(box_cluster)))\n",
    "print('Randomly display 10 boxes then display clustered boxes')\n",
    "choosen_boxes = np.random.randint(n_boxes, size = 10)\n",
    "viz_mayavi_with_labels(lidar, boxes[choosen_boxes])\n",
    "viz_mayavi_with_labels(lidar, box_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predited boxes: 5\n",
      "Number of boxes after clustering: 1\n",
      "Randomly display 10 boxes then display clustered boxes\n"
     ]
    }
   ],
   "source": [
    "#test_dir = './data/test_cars/'\n",
    "test_lidar = np.load('./data/training_didi_data/car_train_edited/suburu_driving_towards_it/lidar/lidar_140.npy')\n",
    "#test_lidar = np.load('./data/test_cars/ford01/lidar_0.npy')\n",
    "boxes, box_cluster = predict(model, test_lidar)\n",
    "n_boxes = len(boxes)\n",
    "print('Number of predited boxes: {}'.format(n_boxes))\n",
    "print('Number of boxes after clustering: {}'.format(len(box_cluster)))\n",
    "print('Randomly display 10 boxes then display clustered boxes')\n",
    "choosen_boxes = np.random.randint(n_boxes, size = 10)\n",
    "viz_mayavi_with_labels(test_lidar, boxes[choosen_boxes])\n",
    "viz_mayavi_with_labels(test_lidar, box_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_bags(model, test_dir, box_test_dir):\n",
    "    '''\n",
    "    This function predict all the test file and save predicted boxes in box_test_dir\n",
    "    '''\n",
    "    if not os.path.exists(box_test_dir):\n",
    "        os.mkdir(box_test_dir)\n",
    "    \n",
    "    bags = os.listdir(test_dir)\n",
    "    for bag in bags:\n",
    "        box_dir = os.path.join(box_test_dir, bag)\n",
    "        if not os.path.exists(box_dir):\n",
    "            os.mkdir(box_dir)\n",
    "        lidar_dir = os.path.join(test_dir, bag)\n",
    "        for f in os.listdir(lidar_dir):\n",
    "            lidar = np.load(os.path.join(lidar_dir,f))\n",
    "            boxes, box_cluster = predict(model, lidar)\n",
    "            f_box = f.replace('lidar', 'boxes')\n",
    "            f_cluster = f.replace('lidar', 'clustered_box')\n",
    "            box_file = os.path.join(box_dir, f_box)\n",
    "            np.save(box_file, boxes)\n",
    "            cluster_file = os.path.join(box_dir, f_cluster)\n",
    "            np.save(cluster_file, box_cluster)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dir = './data/test_cars/'\n",
    "box_test_dir = './data/box_test_cars/'\n",
    "predict_bags(model, test_dir, box_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make top view test video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libpcre.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-72fbbcfe2587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: libpcre.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
